{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e84064",
   "metadata": {},
   "source": [
    "# Cracking the Code: How OpenAI’s O1-Mini Outshines GPT-4o in Trade Processing - Ashish Kumar Jain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff6ed1",
   "metadata": {},
   "source": [
    "## O Series Magic \n",
    "### The idea here is to generate an application when we have a high-level design and want to have a starting point to get ready for a production-ready app. We will generate the app using both GPT4 and O1 models and see what magic O1 reasoning capability is adding to the app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb979589",
   "metadata": {},
   "source": [
    "## The model used in Code Generation\n",
    "\n",
    "### O Series Model (O1- mini) - I will use the o1-mini reasoning model as I still cannot access the o3-mini in my account. As per Open AI Access to o3-mini is rolling out to select API users across trust tiers 3 through 5. They hope to rapidly expand access in the days and weeks ahead. \n",
    "\n",
    "### GPT Model (GPT-4o-mini ) - GPT-4o-mini is a lighter version, optimised for efficiency and cost-effectiveness, likely meant for faster responses with lower computational power. It will help us save some money while running this exercise.\n",
    "\n",
    "\n",
    "#### We will use python code for illustration purpose. You can use this code for your applications. You also need to install below required python library to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1edeeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc652cf0",
   "metadata": {},
   "source": [
    "#### We must load the OpenAI key from the environment variable and set it into api_key. We will get this key while registering with OPENAI. We then instantiate the Open AI client using the key. We will also define two variables for two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "GPT_4O_MINI_MODEL = 'gpt-4o-mini'\n",
    "O1_MINI_MODEL = 'o1-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a0a4bc",
   "metadata": {},
   "source": [
    "#### Let's create some helper function to show the formatted code output in the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc71ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def extract_code_blocks(text):\n",
    "    pattern = r'```(\\w+)?\\n(.*?)```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    code_blocks = {}\n",
    "    for i, (lang, code) in enumerate(matches):\n",
    "        lang = lang.strip() if lang else \"plaintext\"\n",
    "        title = f\"Code Block {i+1} ({lang})\"\n",
    "        code_blocks[title] = f\"```{lang}\\n{code.strip()}\\n```\"\n",
    "    \n",
    "    return code_blocks\n",
    "\n",
    "def format_code(raw_text):\n",
    "    code_blocks = extract_code_blocks(raw_text)\n",
    "    for title, code in code_blocks.items():\n",
    "        display(Markdown(f\"### {title}\\n\"))\n",
    "        display(Markdown(code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387ec7c",
   "metadata": {},
   "source": [
    "## Trade Ordering App\n",
    "\n",
    "### In the financial industry, trading apps allow users to buy, sell, and manage financial instruments such as stocks, bonds, commodities, forex, cryptocurrencies, etc. At the heart of this app is its micro-service architecture style, which has a collection of loosely coupled, independently deployable services, each of which is responsible for a specific business function. These services normally talk to each other using some kind of Enterprise Service Bus (ESB), which sends events to this BUS. This kind of architecture  provides scalability, reliability, and speed in modern trading apps.\n",
    "\n",
    "### We will have three microservices written in different languages. We will tie them together into event-driven architecture using Kafka. We will ask to write stubs for Kafka producers and consumers where we can add our business logic later. We also only generate the Microservices and ESB using Kafka, and for simplicity, we will not have UI elements and other components.\n",
    "\n",
    "### Let's draft our prompt for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8231cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_prompt = \"\"\"\n",
    "Design a trade order management system (TOMS) with the following microservices:\n",
    "\n",
    "order-service (Node.js & Express): Accepts trade orders via REST API, validates them, and publishes to Kafka.\n",
    "\n",
    "risk-service (Python & FastAPI): Listens to new orders, applies pre-trade risk checks, and updates an in-memory risk book.\n",
    "\n",
    "execution-service (Node.js & Express): Picks up risk-approved trades, simulates execution, and sends execution reports.\n",
    "\n",
    "Use PostgreSQL for trade persistence and Redis for real-time risk book updates.\n",
    "Include meaningful stubs for Kafka producers/consumers, but don't implement actual business logic.\n",
    "\n",
    "Respond with the code only! Nothing else!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9eb35",
   "metadata": {},
   "source": [
    "### Let's run the first with the GPT4 model using OPENAI chat completion API and format code output and print that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_gpt4_response = client.chat.completions.create(model=GPT_4O_MINI_MODEL,\n",
    "                                                     messages=[{\"role\":\"user\",\"content\": trade_prompt}])\n",
    "trade_gpt4_code = trade_gpt4_response.choices[0].message.content\n",
    "format_code(trade_gpt4_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151debb",
   "metadata": {},
   "source": [
    "### Now, let's run the same trade prompt on the o1-mini model and see the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f416d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_o1_response = client.chat.completions.create(model=O1_MINI_MODEL,\n",
    "                                                     messages=[{\"role\":\"user\",\"content\": trade_prompt}])\n",
    "trade_o1_code = trade_o1_response.choices[0].message.content\n",
    "format_code(trade_o1_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d1cd8",
   "metadata": {},
   "source": [
    "### We learned earlier that one of the use cases for o1 is Evaluation and benchmarking for other model responses. Now, we can use the o1-mini model to pass the output of both models and do a comparison analysis of both models.\n",
    "\n",
    "#### Now compare the output of both models using o1-mini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524fca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_trade_code_promot = f\"which code is better and why? Option 1: {trade_gpt4_code}... or Option 2: {trade_o1_code}\"\n",
    "better_trade_response = client.chat.completions.create(model=O1_MINI_MODEL,\n",
    "                                                     messages=[{\"role\":\"user\",\"content\": better_trade_code_promot}])\n",
    "better_trade = better_trade_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d966f3",
   "metadata": {},
   "source": [
    "### Let's print the output in the markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(better_trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf09b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
